# ML Algorithms Testing Guide
**Test Plan for ml.js Integration**

---

## ğŸ¯ **What Was Implemented**

### **New Algorithms:**
1. âœ… **Random Forest** - Ensemble method with 100+ trees
2. âœ… **Decision Tree** - Interpretable rules-based classifier
3. âœ… **K-Nearest Neighbors** - Distance-based classification

### **UI Enhancements:**
- Algorithm selection dropdown with 4 options
- Hyperparameter controls for each algorithm
- Algorithm-specific help text and recommendations
- Enhanced result summaries

---

## ğŸ§ª **Testing Checklist**

### **Pre-Testing Setup:**

1. **Start the application:**
   ```bash
   cd /Users/andriy/nexlab
   npm run dev
   ```

2. **Navigate to:**
   - Laboratory Notebook
   - Create or select a Design/Build/Test node
   - Go to "Data Analysis" tab

---

## ğŸ“Š **Test 1: Basic Random Forest**

### **Test Data:**
Download Iris dataset or use this sample:

```csv
sepal_length,sepal_width,petal_length,petal_width,species
5.1,3.5,1.4,0.2,setosa
4.9,3.0,1.4,0.2,setosa
7.0,3.2,4.7,1.4,versicolor
6.4,3.2,4.5,1.5,versicolor
6.3,3.3,6.0,2.5,virginica
5.8,2.7,5.1,1.9,virginica
```

### **Steps:**
1. âœ… Upload CSV file
2. âœ… Click "Run Analysis" tab
3. âœ… Select dataset
4. âœ… Choose "ML: Classification - Random Forest â­"
5. âœ… Select features: sepal_length, sepal_width, petal_length, petal_width
6. âœ… Select target: species
7. âœ… Verify hyperparameters show:
   - Number of Trees: 100 (default)
8. âœ… Set train/test split: 80%
9. âœ… Click "Run Analysis"

### **Expected Results:**
- âœ… Analysis completes in < 5 seconds
- âœ… Accuracy > 85%
- âœ… Confusion matrix displays correctly
- âœ… Feature importance chart appears
- âœ… Summary says "Random Forest (100 trees)"
- âœ… No errors in browser console

---

## ğŸ“Š **Test 2: Decision Tree with Hyperparameters**

### **Steps:**
1. âœ… Use same dataset as Test 1
2. âœ… Choose "ML: Classification - Decision Tree"
3. âœ… Adjust hyperparameters:
   - Max Tree Depth: 5
   - Min Samples per Leaf: 2
4. âœ… Same features and target
5. âœ… Click "Run Analysis"

### **Expected Results:**
- âœ… Analysis completes in < 3 seconds
- âœ… Accuracy > 80%
- âœ… Summary says "Decision Tree (max depth: 5)"
- âœ… Recommendation mentions "adjusting max depth"

---

## ğŸ“Š **Test 3: K-Nearest Neighbors**

### **Steps:**
1. âœ… Use same dataset
2. âœ… Choose "ML: Classification - K-Nearest Neighbors"
3. âœ… Set k=3
4. âœ… Click "Run Analysis"

### **Expected Results:**
- âœ… Analysis completes in < 2 seconds
- âœ… Accuracy > 85%
- âœ… Summary says "K-Nearest Neighbors (k=3)"
- âœ… Recommendation mentions "Try different k values"

---

## ğŸ“Š **Test 4: Logistic Regression (Existing)**

### **Steps:**
1. âœ… Choose "ML: Classification - Logistic Regression"
2. âœ… Use binary classification data (e.g., cancer diagnosis)
3. âœ… Click "Run Analysis"

### **Expected Results:**
- âœ… Still works as before
- âœ… Uses gradient descent
- âœ… Feature normalization applied

---

## ğŸ“Š **Test 5: Algorithm Comparison**

### **Objective:** Compare all 3 new algorithms on the same dataset

### **Steps:**
1. âœ… Run Random Forest â†’ Save analysis as "RF_Test1"
2. âœ… Run Decision Tree â†’ Save analysis as "DT_Test1"
3. âœ… Run KNN â†’ Save analysis as "KNN_Test1"
4. âœ… Go to "Saved Analyses" tab
5. âœ… Click each saved analysis to view results

### **Expected Results:**
- âœ… All 3 analyses saved successfully
- âœ… Can reload and view each one
- âœ… Accuracy differs slightly between algorithms
- âœ… Feature importance shows different rankings

---

## ğŸ“Š **Test 6: Edge Cases**

### **Test 6a: Very Small Dataset (10 rows)**
- âœ… Should work but may warn about overfitting
- âœ… Accuracy might be 100% (overfitting)

### **Test 6b: Large Dataset (10,000 rows)**
- âœ… Should complete in < 10 seconds
- âœ… Random Forest might be slower (~5-10 seconds)
- âœ… No browser crashes

### **Test 6c: Many Features (20+ columns)**
- âœ… All algorithms should handle it
- âœ… Feature importance chart might be cramped

### **Test 6d: Imbalanced Classes (90% class A, 10% class B)**
- âœ… Should complete successfully
- âœ… May show low recall for minority class
- âœ… Recommendation should mention class balancing

---

## ğŸ› **Known Issues / Expected Behavior**

### **Issue 1: Pre-existing TypeScript Errors**
- âœ… lines 230, 346 in dataAnalysisService.ts
- âœ… These are OLD errors, not caused by new code
- âœ… Application still compiles and runs

### **Issue 2: Random Forest is Slower**
- âœ… 100 trees take longer than 1 tree
- âœ… This is expected (trade-off for accuracy)
- âœ… Can reduce trees to 50 for speed

### **Issue 3: Multi-class with Many Classes**
- âœ… Works for 2-50 classes
- âœ… Confusion matrix gets crowded with 10+ classes
- âœ… This is a visualization issue, not algorithm issue

---

## âœ… **Success Criteria**

### **Must Pass:**
- [ ] All 3 new algorithms run without errors
- [ ] Hyperparameter controls update the UI
- [ ] Results are saved and can be reloaded
- [ ] No new TypeScript errors introduced
- [ ] No browser console errors
- [ ] Accuracy is reasonable (> 70% on Iris dataset)

### **Nice to Have:**
- [ ] Performance is acceptable (< 10 seconds)
- [ ] UI is intuitive (no user confusion)
- [ ] Recommendations are helpful

---

## ğŸ“ **Bug Reporting Template**

If you find issues, report them with:

```
**Bug:** [Brief description]
**Algorithm:** [Random Forest / Decision Tree / KNN]
**Dataset:** [File name, size]
**Steps to Reproduce:**
1. ...
2. ...
**Expected:** [What should happen]
**Actual:** [What actually happened]
**Console Errors:** [Copy from browser console]
**Screenshot:** [If relevant]
```

---

## ğŸš€ **Performance Benchmarks**

### **Target Performance:**

| Dataset Size | Random Forest | Decision Tree | KNN |
|--------------|---------------|---------------|-----|
| 100 rows | < 1 second | < 1 second | < 1 second |
| 1,000 rows | < 3 seconds | < 1 second | < 1 second |
| 10,000 rows | < 10 seconds | < 3 seconds | < 2 seconds |

### **Accuracy Targets (Iris Dataset):**

| Algorithm | Min Accuracy | Target Accuracy |
|-----------|--------------|-----------------|
| Random Forest | 90% | 95%+ |
| Decision Tree | 85% | 90%+ |
| KNN | 85% | 93%+ |
| Logistic Regression | 85% | 95%+ |

---

## ğŸ“ **Educational Testing**

### **For Students/Educators:**

**Test Scenario 1: Algorithm Comparison Lesson**
1. Upload the Iris dataset
2. Run all 4 algorithms with default settings
3. Compare accuracies
4. Question: "Which algorithm performs best? Why?"

**Test Scenario 2: Hyperparameter Tuning**
1. Start with Decision Tree, depth=1
2. Gradually increase depth: 2, 5, 10, 20
3. Observe accuracy changes
4. Question: "At what depth do we see diminishing returns?"

**Test Scenario 3: Overfitting Detection**
1. Use Decision Tree with depth=50 on small dataset
2. Compare training vs testing accuracy
3. Question: "Is the model overfitting? How can you tell?"

---

## ğŸ“ **Support**

If you encounter issues:
1. Check browser console for errors
2. Try with a smaller dataset
3. Try with default hyperparameters
4. Refer to `ML_INTEGRATION_QUICKSTART.md` for troubleshooting

---

**Testing Completed:** [ ] Yes [ ] No  
**Date Tested:** ________________  
**Tested By:** ________________  
**Overall Status:** [ ] Pass [ ] Fail [ ] Partial  
**Notes:** ________________________________
